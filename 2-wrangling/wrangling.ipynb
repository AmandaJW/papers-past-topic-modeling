{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Data Wrangling\n",
    "---\n",
    "### Papers Past Topic Modeling\n",
    "\n",
    "<br/>\n",
    "\n",
    "Ben Faulks - bmf43@uclive.ac.nz\n",
    "\n",
    "Xiandong Cai - xca24@uclive.ac.nz\n",
    "\n",
    "Yujie Cui - ycu23@uclive.ac.nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.app.name', 'local'),\n",
      " ('spark.driver.port', '37422'),\n",
      " ('spark.app.id', 'local-1547636455294'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.driver.host', '192.168.1.207'),\n",
      " ('spark.driver.memory', '62g'),\n",
      " ('spark.master', 'local[*]'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.ui.showConsoleProgress', 'true'),\n",
      " ('spark.driver.cores', '6'),\n",
      " ('spark.driver.maxResultSize', '4g')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.207:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=local>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "sys.path.insert(0, '../utils') # for import customed modules\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from utils_data import conf_pyspark, load_dataset\n",
    "\n",
    "# intiate PySpark\n",
    "sc, spark = conf_pyspark()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load raw dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16731578, 6)\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      id|                 url|         publisher|                time|               title|             content|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|16697801|http://api.digita...|Poverty Bay Herald|1918-09-02T00:00:...|GRAIN GOES FOR VO...|GRAIN GOES FOR VO...|\n",
      "|16768825|http://api.digita...|Poverty Bay Herald|1919-10-30T00:00:...|LAWS AGAINST ALIE...|LAWS AGAINST ALIE...|\n",
      "| 4291037|http://api.digita...| Manawatu Standard|1886-06-09T00:00:...|Page 4 Advertisem...|ROBERT JOHNSON & ...|\n",
      "| 2095870|http://api.digita...|      Bruce Herald|1873-08-05T00:00:...|Page 2 Advertisem...|MISOELLAITEOUS. A...|\n",
      "| 2348163|http://api.digita...|      Bruce Herald|1877-01-16T00:00:...|Page 8 Advertisem...|1 NEW ADVERTISE M...|\n",
      "|11049559|http://api.digita...|       Thames Star|1896-06-29T00:00:...|Soudan and Abyssi...|Soudan and Abyssi...|\n",
      "|12004329|http://api.digita...|       Thames Star|1899-06-14T00:00:...|AUCKLAND SHAREMAR...|AUCKLAND SHAREMAR...|\n",
      "| 3598084|http://api.digita...|       Thames Star|1898-09-22T00:00:...|Fatal Fire. (Tham...|Fatal Fire.Press ...|\n",
      "|15846537|http://api.digita...|   Wanganui Herald|1908-09-25T00:00:...|Page 4 Advertisem...|The Prices at Han...|\n",
      "|16006172|http://api.digita...|   Wanganui Herald|1909-10-06T00:00:...|INQUESTS (Wanganu...|INQUESTS(Por Unit...|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset('papers_past', spark)\n",
    "\n",
    "nrow_raw = df.count()\n",
    "print('Shape of dataframe: ({}, {})'.format(nrow_raw, len(df.columns)))\n",
    "df.sample(False, 0.00001).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check empty values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+\n",
      "| id|url|publisher|time|title|content|\n",
      "+---+---+---------+----+-----+-------+\n",
      "|  0|  0|        0|   0|    0|  56232|\n",
      "+---+---+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows with empty document:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NA to avoid nonetype.\n",
    "df = df.na.drop(subset=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+\n",
      "| id|url|publisher|time|title|content|\n",
      "+---+---+---------+----+-----+-------+\n",
      "|  0|  0|        0|   0|    0|      0|\n",
      "+---+---+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The \"id\" should be unique, check duplication:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated id number:  543700\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated id number: ', df.count() - df.select('id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are duplicated \"id\" in the dataset, show three of them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|      id|count|\n",
      "+--------+-----+\n",
      "|10036037|    2|\n",
      "|10059447|    2|\n",
      "|10099968|    2|\n",
      "+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id').count().where(F.col('count')>1).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the first one to check detail:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      id|                 url|         publisher|                time|               title|             content|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|10036037|http://api.digita...|Poverty Bay Herald|1898-01-06T00:00:...|THE EASTERN SITUA...|THE EASTERN SITUA...|\n",
      "|10036037|http://api.digita...|Poverty Bay Herald|1898-01-06T00:00:...|THE EASTERN SITUA...|THE EASTERN SITUA...|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.id == 10036037).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check difference of the content:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:  0.9994846688997681\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "str1 = df.filter(df.id == 10036037).select('content').collect()[0]['content']\n",
    "#print(str1 + '\\n')\n",
    "\n",
    "str2 = df.filter(df.id == 10036037).select('content').collect()[1]['content']\n",
    "#print(str2 + '\\n')\n",
    "\n",
    "diff = difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "print('Similarity: ', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The two duplicates are very close, drop one of them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check duplicate again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated id number:  0\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated id number: ', df.count() - df.select('id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Abnormal Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There should be 68 publishers, check numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "Correct! no abnormal values in publishers.\n"
     ]
    }
   ],
   "source": [
    "n = df.select('publisher').distinct().count()\n",
    "print(n)\n",
    "if n == 68:\n",
    "    print('Correct! no abnormal values in publishers.')\n",
    "else:\n",
    "    print('Error! abnormal values in publishers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For history documents, it only need date as time unit, we extract \"date\" column from \"time\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature date\n",
    "df = df.withColumn('date', df['time'].cast(DateType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check schema of the dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check date range has abnormal values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1839, 8, 21), datetime.date(1945, 12, 31))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = df.select(F.min('date'), F.max('date')).first()\n",
    "start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Advertisements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check \"title\" column to see if it is possible to extract features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------------------------------------------------------------------------+\n",
      "|id      |date      |title                                                                      |\n",
      "+--------+----------+---------------------------------------------------------------------------+\n",
      "|18037863|1926-02-15|TIVOLI THEATRE. (Evening Post, 15 February 1926)                           |\n",
      "|17084305|1918-03-02|WAR BREAD IN SOUTH AFRICA (Evening Post, 02 March 1918)                    |\n",
      "|3765185 |1871-07-05|TIMARU PRICES CURRENT. (Timaru Herald, 05 July 1871)                       |\n",
      "|25313950|1911-12-12|Page 6 Advertisements Column 3 (Marlborough Express, 12 December 1911)     |\n",
      "|26110715|1913-02-24|WELLINGTON PROVINCIAL CHAMPIONSHIPS. (Wanganui Chronicle, 24 February 1913)|\n",
      "|25648863|1920-09-11|Page 5 Advertisements Column 5 (Marlborough Express, 11 September 1920)    |\n",
      "|4363888 |1876-08-29|LONDON. (North Otago Times, 29 August 1876)                                |\n",
      "|11114259|1892-09-13|Page 2 Advertisements Column 1 (West Coast Times, 13 September 1892)       |\n",
      "|16702941|1918-11-06|SOMME HOUSE FOR KAISER. (Poverty Bay Herald, 06 November 1918)             |\n",
      "|26146851|1914-07-07|Page 2 Advertisements Column 5 (Wanganui Chronicle, 07 July 1914)          |\n",
      "+--------+----------+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.00001).limit(10).select('id', 'date', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The \"title\" column specified advertisement, we extract \"ads\" column from \"title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------------------------------------------------------------------------+\n",
      "|id      |ads  |title                                                                   |\n",
      "+--------+-----+------------------------------------------------------------------------+\n",
      "|6447022 |false|THE WESTLAND EDUCATION  ORDINANCE, 1874. (West Coast Times, 16 May 1874)|\n",
      "|8592655 |false|LOCAL AND GENERAL. (Wanganui Chronicle, 18 April 1888)                  |\n",
      "|19764103|true |Page 2 Advertisements Column 2 (Evening Post, 21 January 1916)          |\n",
      "|14595762|true |Page 9 Advertisements Column 2 (Poverty Bay Herald, 28 September 1910)  |\n",
      "|12177897|true |Page 2 Advertisements Column 4 (Southland Times, 24 September 1900)     |\n",
      "|2684218 |true |Page 4 Advertisements Column 3 (Evening Post, 30 December 1898)         |\n",
      "|3714082 |false|A QUESTION OF DAILY WORK. (Clutha Leader, 17 March 1899)                |\n",
      "|12186854|false|FIRE. (Ashburton Guardian, 07 January 1911)                             |\n",
      "|15896242|false|THE BALKAN RAILWAY. (Wanganui Herald, 25 February 1908)                 |\n",
      "|15713665|false|OTIRA TRAIN SMASH. (Poverty Bay Herald, 07 May 1913)                    |\n",
      "+--------+-----+------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract feature ads\n",
    "df = df.withColumn('ads', df.title.contains('dvertisement'))\n",
    "\n",
    "df.sample(False, 0.00001).limit(10).select('id', 'ads', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The title consists of three parts: \"real title\" (\"publisher\", \"date\"), we only need \"real title\" part. Extract real title:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redandunt parts of title\n",
    "df = df.withColumn('title_', F.regexp_extract(F.col('title'), '(.*)(\\s\\(.*\\))', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if some titles are not the form \"title (\"publisher\", \"date\"), which will lead to \"title_\" column is empty string:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------------------+\n",
      "|id      |title_|title                |\n",
      "+--------+------+---------------------+\n",
      "|3656781 |      |Untitled Illustration|\n",
      "|4832017 |      |Untitled Illustration|\n",
      "|5417742 |      |Untitled Illustration|\n",
      "|12676570|      |Untitled Illustration|\n",
      "|12777321|      |Untitled Illustration|\n",
      "+--------+------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(F.col('title_') == '').select(['id', 'title_', 'title']).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change empty string in \"title_\" column to \"Untitled Illustration\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'title_',\n",
    "    F.when(\n",
    "        F.col('title_') == '',\n",
    "        F.lit('Untitled Illustration')\n",
    "    ).otherwise(\n",
    "        F.col('title_')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check empty string again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "| id|url|publisher|time|title|content|date|ads|title_|\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "|  0|  0|        0|   0|    0|      0|   0|  0|     0|\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print title columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|      id|              title_|               title|\n",
      "+--------+--------------------+--------------------+\n",
      "|18396556|Page 6 Advertisem...|Page 6 Advertisem...|\n",
      "|25314717|Page 5 Advertisem...|Page 5 Advertisem...|\n",
      "| 3884919|New Zealand Provi...|New Zealand Provi...|\n",
      "|16123212|  MILK FOR INVALIDS.|MILK FOR INVALIDS...|\n",
      "|17074845|   LOOK WHO'S HERE.\"|LOOK WHO'S HERE.\"...|\n",
      "| 8996651|UNDERHAND BORROWING.|UNDERHAND BORROWI...|\n",
      "|26599538|JAPANESE NAVY EST...|JAPANESE NAVY EST...|\n",
      "| 6391703|ROAD BOARD ELECTION.|ROAD BOARD ELECTI...|\n",
      "|16313874|   LETTERS TO EDITOR|LETTERS TO EDITOR...|\n",
      "|29029266|            Bowling.|Bowling. (Daily T...|\n",
      "+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.00001).limit(10).select('id', 'title_', 'title').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the website of [Papers Past](https://paperspast.natlib.govt.nz), we could find the publisher-region relationship in the [Explore all newspapers](https://paperspast.natlib.govt.nz/newspapers/all#region) webpage. Based on this webpage, we could extract region feature from \"publisher\" column. Here we saved [the webpage](https://paperspast.natlib.govt.nz/newspapers/all#region) and crawling the publisher-region relationship into a dataframe for extract feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# read webpage\n",
    "path = r'../temp/Papers Past _ Explore all newspapers.html'\n",
    "with open(path, 'r') as f:\n",
    "    html = f.read()\n",
    "\n",
    "# get table \n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "table = soup.find('table', attrs={'class':'table datatable'})\n",
    "table_rows = table.find_all('tr')\n",
    "res = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text.strip() for tr in td if tr.text.strip()]\n",
    "    if row:\n",
    "        res.append(row)\n",
    "\n",
    "# transform table to pandas dataframe\n",
    "df_region = pd.DataFrame(res, columns=['publisher_', 'region', 'start_', 'end_']) # column_ means it will be drop later\n",
    "\n",
    "# transform pandas dataframe to pyspark dataframe\n",
    "df_region = spark.createDataFrame(df_region).orderBy('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (148, 4)\n",
      "+-------------------------------------------------+-----------------+------+----+\n",
      "|publisher_                                       |region           |start_|end_|\n",
      "+-------------------------------------------------+-----------------+------+----+\n",
      "|Te Puke Times                                    |Bay of Plenty    |1913  |1920|\n",
      "|Oxford Observer                                  |Canterbury       |1889  |1901|\n",
      "|Timaru Herald                                    |Canterbury       |1864  |1920|\n",
      "|Horowhenua Chronicle                             |Manawatu-Wanganui|1910  |1939|\n",
      "|Manawatu Standard                                |Manawatu-Wanganui|1883  |1923|\n",
      "|Anglo-Maori Warder                               |National         |1848  |1848|\n",
      "|Maoriland Worker                                 |National         |1910  |1924|\n",
      "|New Zealand Advertiser and Bay of Islands Gazette|Northland        |1840  |1840|\n",
      "|Otago Daily Times                                |Otago            |1861  |1950|\n",
      "|Waihi Daily Telegraph                            |Waikato          |1904  |1944|\n",
      "+-------------------------------------------------+-----------------+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dataframe: ({}, {})'.format(df_region.count(), len(df_region.columns)))\n",
    "df_region.sample(False, 0.1).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that in this publisher-region relationship dataframe, there are two publisher's name is not identical with the dataset: \"Bay Of Plenty Times\" mismatch by \"of\", \"New Zealand Free Lance\" mismatch by \"New Zeland\", so we modify the** `df_region` **to make it identical with dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------+----+\n",
      "|publisher_         |region       |start_|end_|\n",
      "+-------------------+-------------+------+----+\n",
      "|Bay of Plenty Times|Bay of Plenty|1872  |1949|\n",
      "|Free Lance         |Wellington   |1900  |1920|\n",
      "+-------------------+-------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_region.filter((df_region.publisher_ == 'Bay of Plenty Times')\n",
    "                 | (df_region.publisher_ == 'Free Lance'))\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df_region for Bay Of Plenty Times and New Zealand Free Lance\n",
    "df_region = df_region.withColumn(\n",
    "    'publisher_',\n",
    "    F.when(\n",
    "        F.col('publisher_') == 'Bay of Plenty Times',\n",
    "        F.lit('Bay Of Plenty Times')\n",
    "    ).otherwise(\n",
    "        F.col('publisher_')\n",
    "    )\n",
    ").withColumn(\n",
    "    'publisher_',\n",
    "    F.when(\n",
    "        F.col('publisher_') == 'Free Lance',\n",
    "        F.lit('New Zealand Free Lance')\n",
    "    ).otherwise(\n",
    "        F.col('publisher_')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if the two publishers' name were modified:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+------+----+\n",
      "|publisher_            |region       |start_|end_|\n",
      "+----------------------+-------------+------+----+\n",
      "|Bay Of Plenty Times   |Bay of Plenty|1872  |1949|\n",
      "|New Zealand Free Lance|Wellington   |1900  |1920|\n",
      "+----------------------+-------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_region.filter((df_region.publisher_ == 'Bay Of Plenty Times')\n",
    "                 | (df_region.publisher_ == 'New Zealand Free Lance'))\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract region column, and abandon redundant columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.join(df_region, df.publisher == df_region.publisher_, how='left')\n",
    "      .select(F.col('id'), \n",
    "              F.col('publisher'), \n",
    "              F.col('region'), \n",
    "              F.col('date'), \n",
    "              F.col('ads'), \n",
    "              F.col('title_').alias('title'), \n",
    "              F.col('content'))\n",
    "      .orderBy('id')\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing missing value in region column with \"unknwon\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill({'region':'unknown'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if miss any field or element:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null and empty string:\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "| id|publisher|region|date|ads|title|content|\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "|  0|        0|     0|   0|  0|    0|      0|\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print Null and empty string:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check dataframe szie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16131646, 7)\n",
      "usable line percentage: 0.9641437287026962\n",
      "removed line number: 599932\n"
     ]
    }
   ],
   "source": [
    "nrow = df.count()\n",
    "print('Shape of dataframe: ({}, {})'.format(nrow, len(df.columns)))\n",
    "print('usable line percentage:', nrow/nrow_raw)\n",
    "print('removed line number:', nrow_raw - nrow)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After data wrangling, there are:**\n",
    "* 16,131,646 (96.4%) samples/rows/lines/documents usable, \n",
    "* 599,932 samples/rows/lines/documents were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print schema and dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- region: string (nullable = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- ads: boolean (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|     id|           publisher|           region|      date|  ads|               title|             content|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|2022138|  Hawke's Bay Herald|      Hawke's Bay|1862-05-13|false|HAWKE'S BAY HERAL...|HAWKE'S BAY HERAL...|\n",
      "|2141642|        Bruce Herald|            Otago|1874-01-23|false|The Bruce Herald....|The Bruce Herald....|\n",
      "|2161886|    Grey River Argus|       West Coast|1868-08-18| true|Page 1 Advertisem...|Tt/TE. A. 11. GUI...|\n",
      "|2268419|    Grey River Argus|       West Coast|1869-06-24|false|         AMUSEMENTS.|AMUSEMENTS.Allian...|\n",
      "|2395450|Hawera & Normanby...|         Taranaki|1884-07-23|false|           WESTLAND.|WESTLAND.GREYMOUT...|\n",
      "|2499703|        Bruce Herald|            Otago|1879-03-28| true|Page 2 Advertisem...|HENDERSON & FERGU...|\n",
      "|2534496|       Bush Advocate|      Hawke's Bay|1902-11-04|false|       South Africa.|b'South Africa.(U...|\n",
      "|3058934|New Zealand Spect...|       Wellington|1854-02-01|false|PROVINCIAL COUNCI...|PROVINCIAL COUNCI...|\n",
      "|3231073|       Otago Witness|            Otago|1857-11-07| true|Page 8 Advertisem...|4 ON SALE, . , EX...|\n",
      "|3330045| Bay Of Plenty Times|    Bay of Plenty|1888-10-26|false|German Brutality ...|German Brutality ...|\n",
      "|3488419|Otautau Standard ...|            Otago|1912-10-08| true|Page 5 Advertisem...|The Southland Edu...|\n",
      "|3594591|            NZ Truth|         National|1911-08-12|false|            Untitled|Latest English pa...|\n",
      "|3622879|     Wanganui Herald|Manawatu-Wanganui|1877-01-23|false|  COLONIAL TELEGRAMS|COLONIAL TELEGRAM...|\n",
      "|3703540|Nelson Examiner a...|           Nelson|1862-08-27| true|Page 2 Advertisem...|PROSPECTUS. NELSO...|\n",
      "|3778811|         Thames Star|          Waikato|1898-08-01|false|General Merritt's...|General Merritt's...|\n",
      "|3808398|         Thames Star|          Waikato|1898-08-12|false|County Councils' ...|County Councils' ...|\n",
      "|3946106|Hawera & Normanby...|         Taranaki|1888-05-26|false|               GOLD!|GOLD!BLENHEIM, Ma...|\n",
      "|3958363|      Mataura Ensign|            Otago|1894-09-25| true|Page 6 Advertisem...|. General Adverti...|\n",
      "|3992328|  Wanganui Chronicle|Manawatu-Wanganui|1876-06-24|false|SHIPPING INTELLIG...|SHIPPING INTELLIG...|\n",
      "|4030963|     Manawatu Herald|Manawatu-Wanganui|1895-04-23| true|Page 4 Advertisem...|IMPORTANT NOTICE....|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.sample(False, 0.00001).limit(20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Save Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataframe would be our final dataset to deal with, let's save it as compressed csv file to save time for later processes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../data/dataset'\n",
    "df.write.csv(path, mode='overwrite', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the clean dataset size:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw   dataset size: 33G\n",
      "clean dataset size: 14G\n"
     ]
    }
   ],
   "source": [
    "path = r'../data/papers_past'\n",
    "print('raw   dataset size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))\n",
    "path = r'../data/dataset'\n",
    "print('clean dataset size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After processing and compressing, the dataset reduce from 33GB to 14GB.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
