{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Data Wrangling\n",
    "---\n",
    "### Papers Past Topic Modeling\n",
    "\n",
    "<br/>\n",
    "\n",
    "Ben Faulks - bmf43@uclive.ac.nz\n",
    "\n",
    "Xiandong Cai - xca24@uclive.ac.nz\n",
    "\n",
    "Yujie Cui - ycu23@uclive.ac.nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.driver.port', '45024'),\n",
      " ('spark.app.id', 'local-1547694941045'),\n",
      " ('spark.app.name', 'local'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.driver.host', '192.168.1.207'),\n",
      " ('spark.driver.memory', '62g'),\n",
      " ('spark.master', 'local[*]'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.ui.showConsoleProgress', 'true'),\n",
      " ('spark.driver.cores', '6'),\n",
      " ('spark.driver.maxResultSize', '4g')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.207:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=local>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "sys.path.insert(0, '../utils') # for import customed modules\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from utils_data import conf_pyspark, load_dataset\n",
    "\n",
    "# intiate PySpark\n",
    "sc, spark = conf_pyspark()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load raw dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16731578, 6)\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      id|                 url|         publisher|                time|               title|             content|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|14479009|http://api.digita...|Poverty Bay Herald|1910-11-12T00:00:...|TOWN EDITION. (Po...|TOWN EDITION.A ma...|\n",
      "|15564607|http://api.digita...|Poverty Bay Herald|1913-10-11T00:00:...|Page 1 Advertisem...|HUDuART-PARKER LI...|\n",
      "| 3592912|http://api.digita...|Poverty Bay Herald|1879-06-14T00:00:...|Page 2 Advertisem...|She springs from'...|\n",
      "| 6732646|http://api.digita...|Poverty Bay Herald|1887-11-26T00:00:...|THE SCANDAL IN PA...|THE SCANDAL IN PA...|\n",
      "| 4720741|http://api.digita...|     Tuapeka Times|1879-03-22T00:00:...|THE FIELD OF INVE...|THE FIELD OF INVE...|\n",
      "|34135105|http://api.digita...|    Mataura Ensign|1908-11-23T12:00:00Z|Page 3 Advertisem...|Soros, Burns, Ulc...|\n",
      "| 2409932|http://api.digita...|      Bruce Herald|1878-01-08T00:00:...|Original Correspo...|Original Correspo...|\n",
      "| 5170406|http://api.digita...|      Bruce Herald|1892-03-18T00:00:...|Untitled (Bruce H...|The record in eng...|\n",
      "| 3092215|http://api.digita...|          NZ Truth|1909-07-03T00:00:...|JENNINGS JILTED. ...|JENNINGS JILTED.M...|\n",
      "| 3969134|http://api.digita...|          NZ Truth|1913-05-24T00:00:...|Page 7 Advertisem...|The RHOFSERIES ED...|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset('papers_past', spark)\n",
    "\n",
    "nrow_raw = df.count()\n",
    "print('Shape of dataframe: ({}, {})'.format(nrow_raw, len(df.columns)))\n",
    "df.sample(False, 0.00001).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check empty values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+\n",
      "| id|url|publisher|time|title|content|\n",
      "+---+---+---------+----+-----+-------+\n",
      "|  0|  0|        0|   0|    0|  56232|\n",
      "+---+---+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows with empty document:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NA to avoid nonetype.\n",
    "df = df.na.drop(subset=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+\n",
      "| id|url|publisher|time|title|content|\n",
      "+---+---+---------+----+-----+-------+\n",
      "|  0|  0|        0|   0|    0|      0|\n",
      "+---+---+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The \"id\" should be unique, check duplication:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated id number:  543700\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated id number: ', df.count() - df.select('id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are duplicated \"id\" in the dataset, show three of them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|      id|count|\n",
      "+--------+-----+\n",
      "|10036037|    2|\n",
      "|10059447|    2|\n",
      "|10099968|    2|\n",
      "+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id').count().where(F.col('count')>1).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the first one to check detail:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      id|                 url|         publisher|                time|               title|             content|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|10036037|http://api.digita...|Poverty Bay Herald|1898-01-06T00:00:...|THE EASTERN SITUA...|THE EASTERN SITUA...|\n",
      "|10036037|http://api.digita...|Poverty Bay Herald|1898-01-06T00:00:...|THE EASTERN SITUA...|THE EASTERN SITUA...|\n",
      "+--------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.id == 10036037).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check difference of the content:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:  0.9994846688997681\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "str1 = df.filter(df.id == 10036037).select('content').collect()[0]['content']\n",
    "#print(str1 + '\\n')\n",
    "\n",
    "str2 = df.filter(df.id == 10036037).select('content').collect()[1]['content']\n",
    "#print(str2 + '\\n')\n",
    "\n",
    "diff = difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "print('Similarity: ', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The two duplicates are very close, drop one of them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check duplicate again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated id number:  0\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated id number: ', df.count() - df.select('id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Abnormal Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There should be 68 publishers, check numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "Correct! no abnormal values in publishers.\n"
     ]
    }
   ],
   "source": [
    "n = df.select('publisher').distinct().count()\n",
    "print(n)\n",
    "if n == 68:\n",
    "    print('Correct! no abnormal values in publishers.')\n",
    "else:\n",
    "    print('Error! abnormal values in publishers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For history documents, it only need date as time unit, we extract \"date\" column from \"time\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature date\n",
    "df = df.withColumn('date', df['time'].cast(DateType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check schema of the dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check date range has abnormal values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1839, 8, 21), datetime.date(1945, 12, 31))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = df.select(F.min('date'), F.max('date')).first()\n",
    "start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Advertisements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check \"title\" column to see if it is possible to extract features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------------------------------------------------+\n",
      "|id      |date      |title                                                       |\n",
      "+--------+----------+------------------------------------------------------------+\n",
      "|33583964|1901-08-17|TELEGRAMS. (Otago Daily Times 17-8-1901)                    |\n",
      "|6577219 |1901-03-25|AN UNFORTUNATE MISTAKE. (Bay Of Plenty Times, 25 March 1901)|\n",
      "|28322435|1893-04-07|CARNEGIE'S EMPLOYEES. (Auckland Star, 07 April 1893)        |\n",
      "|13133895|1902-06-06|Telegraphic News. (Thames Star, 06 June 1902)               |\n",
      "|18336280|1927-05-03|Page 14 Advertisements Column 2 (Evening Post, 03 May 1927) |\n",
      "|2918534 |1862-11-18|WATER SUPPLY. (Otago Daily Times, 18 November 1862)         |\n",
      "|28183893|1890-07-25|TELEGRAPHIC\" SHIPPING. (Auckland Star, 25 July 1890)        |\n",
      "|7228753 |1883-01-06|Gossipy Paragraphs. (Otago Witness, 06 January 1883)        |\n",
      "|16698477|1918-09-07|THE BATTIE FRONT. (Poverty Bay Herald, 07 September 1918)   |\n",
      "|2811594 |1884-01-21|HOPS. (Colonist, 21 January 1884)                           |\n",
      "+--------+----------+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.00001).limit(10).select('id', 'date', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The \"title\" column specified advertisement, we extract \"ads\" column from \"title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-------------------------------------------------------------------------------------------------------+\n",
      "|id      |ads  |title                                                                                                  |\n",
      "+--------+-----+-------------------------------------------------------------------------------------------------------+\n",
      "|8806818 |true |Page 2 Advertisements Column 7 (Feilding Star, 30 April 1903)                                          |\n",
      "|13809064|false|EXTRACT. (Taranaki Herald, 23 September 1903)                                                          |\n",
      "|5708215 |false|CHRISTMAS. (Wanganui Herald, 24 December 1881)                                                         |\n",
      "|18654017|false|MOVING SOUTHWARDS (Evening Post, 23 September 1942)                                                    |\n",
      "|2736372 |false|THE NELSON EXAMINER. Nelson, April 17, 1852. (Nelson Examiner and New Zealand Chronicle, 17 April 1852)|\n",
      "|8645373 |false|POLITICAL REFORM. (Evening Post, 28 June 1909)                                                         |\n",
      "|13300699|false|PERSIA. (Ashburton Guardian, 03 June 1912)                                                             |\n",
      "|14827568|true |Page 2 Advertisements Column 2 (West Coast Times, 09 July 1909)                                        |\n",
      "|29236082|false|CARTERTON NEWS. (Wairarapa Daily Times, 22 July 1902)                                                  |\n",
      "|5406634 |false|Drowned in the Rakaia. (Ashburton Guardian, 07 October 1895)                                           |\n",
      "+--------+-----+-------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract feature ads\n",
    "df = df.withColumn('ads', df.title.contains('dvertisement'))\n",
    "\n",
    "df.sample(False, 0.00001).limit(10).select('id', 'ads', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The title consists of three parts: \"real title\" (\"publisher\", \"date\"), we only need \"real title\" part. Extract real title:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redandunt parts of title\n",
    "df = df.withColumn('title_', F.regexp_extract(F.col('title'), '(.*)(\\s\\(.*\\))', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if some titles are not the form \"title (\"publisher\", \"date\"), which will lead to \"title_\" column is empty string:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------------------+\n",
      "|id      |title_|title                |\n",
      "+--------+------+---------------------+\n",
      "|3656781 |      |Untitled Illustration|\n",
      "|4832017 |      |Untitled Illustration|\n",
      "|5417742 |      |Untitled Illustration|\n",
      "|12676570|      |Untitled Illustration|\n",
      "|12777321|      |Untitled Illustration|\n",
      "+--------+------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(F.col('title_') == '').select(['id', 'title_', 'title']).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change empty string in \"title_\" column to \"Untitled Illustration\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'title_',\n",
    "    F.when(\n",
    "        F.col('title_') == '',\n",
    "        F.lit('Untitled Illustration')\n",
    "    ).otherwise(\n",
    "        F.col('title_')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check empty string again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null:\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "| id|url|publisher|time|title|content|date|ads|title_|\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "|  0|  0|        0|   0|    0|      0|   0|  0|     0|\n",
      "+---+---+---------+----+-----+-------+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null\n",
    "print('Print Null:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print title columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "|id      |title_                                                          |title                                                                                            |\n",
      "+--------+----------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "|20077538|FOURTEEN VESSELS                                                |FOURTEEN VESSELS (Evening Post, 29 September 1941)                                               |\n",
      "|32535786|CABLE MESSAGES                                                  |CABLE MESSAGES (Otago Daily Times 2-12-1910)                                                     |\n",
      "|10261389|AUSTRALIAN. SYDNEY UNDER A CLOUD. HARVEST PROSPECTS IN VICTORIA.|AUSTRALIAN. SYDNEY UNDER A CLOUD. HARVEST PROSPECTS IN VICTORIA. (Evening Post, 26 November 1888)|\n",
      "|3595355 |Page 1 Advertisements Column 3                                  |Page 1 Advertisements Column 3 (Bruce Herald, 29 February 1884)                                  |\n",
      "|26658773|SCIENTIFIC AND INDUSTRIAL RESEARCH.                             |SCIENTIFIC AND INDUSTRIAL RESEARCH. (Colonist, 04 December 1916)                                 |\n",
      "|2723654 |Page 6 Advertisements Column 1                                  |Page 6 Advertisements Column 1 (Ohinemuri Gazette, 16 July 1892)                                 |\n",
      "|26143279|Page 7 Advertisements Column 4                                  |Page 7 Advertisements Column 4 (Wanganui Chronicle, 24 November 1913)                            |\n",
      "|2437244 |Page 8 Advertisements Column 1                                  |Page 8 Advertisements Column 1 (Bruce Herald, 24 September 1878)                                 |\n",
      "|11818337|CABLE BREVITIES.                                                |CABLE BREVITIES. (Thames Star, 30 March 1899)                                                    |\n",
      "|26864072|SCENIC DESTRUCTION.                                             |SCENIC DESTRUCTION. (Northern Advocate, 21 November 1910)                                        |\n",
      "+--------+----------------------------------------------------------------+-------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.00001).limit(10).select('id', 'title_', 'title').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the website of [Papers Past](https://paperspast.natlib.govt.nz), we could find the publisher-region relationship in the [Explore all newspapers](https://paperspast.natlib.govt.nz/newspapers/all#region) webpage. Based on this webpage, we could extract region feature from \"publisher\" column. Here we saved [the webpage](https://paperspast.natlib.govt.nz/newspapers/all#region) and crawling the publisher-region relationship into a dataframe for extract feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# read webpage\n",
    "path = r'../temp/Papers Past _ Explore all newspapers.html'\n",
    "with open(path, 'r') as f:\n",
    "    html = f.read()\n",
    "\n",
    "# get table \n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "table = soup.find('table', attrs={'class':'table datatable'})\n",
    "table_rows = table.find_all('tr')\n",
    "res = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text.strip() for tr in td if tr.text.strip()]\n",
    "    if row:\n",
    "        res.append(row)\n",
    "\n",
    "# transform table to pandas dataframe\n",
    "df_region = pd.DataFrame(res, columns=['publisher_', 'region', 'start_', 'end_']) # column_ means it will be drop later\n",
    "\n",
    "# transform pandas dataframe to pyspark dataframe\n",
    "df_region = spark.createDataFrame(df_region).orderBy('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (148, 4)\n",
      "+-------------------+-----------------+------+----+\n",
      "|publisher_         |region           |start_|end_|\n",
      "+-------------------+-----------------+------+----+\n",
      "|Albertland Gazette |Auckland         |1862  |1864|\n",
      "|Hot Lakes Chronicle|Bay of Plenty    |1895  |1910|\n",
      "|Ashburton Guardian |Canterbury       |1879  |1921|\n",
      "|Ellesmere Guardian |Canterbury       |1891  |1945|\n",
      "|Globe              |Canterbury       |1874  |1882|\n",
      "|Matariki           |Gisborne         |1881  |1881|\n",
      "|Feilding Star      |Manawatu-Wanganui|1882  |1920|\n",
      "|Nelson Evening Mail|Nelson           |1866  |1922|\n",
      "|Bruce Herald       |Otago            |1865  |1920|\n",
      "|Lake County Press  |Otago            |1872  |1928|\n",
      "+-------------------+-----------------+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dataframe: ({}, {})'.format(df_region.count(), len(df_region.columns)))\n",
    "df_region.sample(False, 0.1).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that in this publisher-region relationship dataframe, there are two publisher's name is not identical with the dataset: \"Bay Of Plenty Times\" mismatch by \"of\", \"New Zealand Free Lance\" mismatch by \"New Zeland\", so we modify the** `df_region` **to make it identical with dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------+----+\n",
      "|publisher_         |region       |start_|end_|\n",
      "+-------------------+-------------+------+----+\n",
      "|Bay of Plenty Times|Bay of Plenty|1872  |1949|\n",
      "|Free Lance         |Wellington   |1900  |1920|\n",
      "+-------------------+-------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_region.filter((df_region.publisher_ == 'Bay of Plenty Times')\n",
    "                 | (df_region.publisher_ == 'Free Lance'))\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df_region for Bay Of Plenty Times and New Zealand Free Lance\n",
    "df_region = df_region.withColumn(\n",
    "    'publisher_',\n",
    "    F.when(\n",
    "        F.col('publisher_') == 'Bay of Plenty Times',\n",
    "        F.lit('Bay Of Plenty Times')\n",
    "    ).otherwise(\n",
    "        F.col('publisher_')\n",
    "    )\n",
    ").withColumn(\n",
    "    'publisher_',\n",
    "    F.when(\n",
    "        F.col('publisher_') == 'Free Lance',\n",
    "        F.lit('New Zealand Free Lance')\n",
    "    ).otherwise(\n",
    "        F.col('publisher_')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if the two publishers' name were modified:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+------+----+\n",
      "|publisher_            |region       |start_|end_|\n",
      "+----------------------+-------------+------+----+\n",
      "|Bay Of Plenty Times   |Bay of Plenty|1872  |1949|\n",
      "|New Zealand Free Lance|Wellington   |1900  |1920|\n",
      "+----------------------+-------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_region.filter((df_region.publisher_ == 'Bay Of Plenty Times')\n",
    "                 | (df_region.publisher_ == 'New Zealand Free Lance'))\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the dataframe for later use:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../temp/region.csv'\n",
    "\n",
    "(df_region.select(F.col('publisher_'),\n",
    "                  F.col('region'))\n",
    " .toPandas()\n",
    " .to_csv(path, header=False, index=False, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract region column, and abandon redundant columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.join(df_region, df.publisher == df_region.publisher_, how='left')\n",
    "      .select(F.col('id'), \n",
    "              F.col('publisher'), \n",
    "              F.col('region'), \n",
    "              F.col('date'), \n",
    "              F.col('ads'), \n",
    "              F.col('title_').alias('title'), \n",
    "              F.col('content'))\n",
    "      .orderBy('id')\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing missing value in region column with \"unknwon\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill({'region':'unknown'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if miss any field or element:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Null and empty string:\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "| id|publisher|region|date|ads|title|content|\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "|  0|        0|     0|   0|  0|    0|      0|\n",
      "+---+---------+------+----+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print Null and empty string:')\n",
    "df.select([F.count(F.when(F.col(c).isNull() | (F.col(c) == ''), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check dataframe szie:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16131646, 7)\n",
      "usable line percentage: 0.9641437287026962\n",
      "removed line number: 599932\n"
     ]
    }
   ],
   "source": [
    "nrow = df.count()\n",
    "print('Shape of dataframe: ({}, {})'.format(nrow, len(df.columns)))\n",
    "print('usable line percentage:', nrow/nrow_raw)\n",
    "print('removed line number:', nrow_raw - nrow)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After data wrangling, there are:**\n",
    "* 16,131,646 (96.4%) samples/rows/lines/documents usable, \n",
    "* 599,932 samples/rows/lines/documents were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print schema and dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- region: string (nullable = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- ads: boolean (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|     id|           publisher|           region|      date|  ads|               title|             content|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|1948954|       Clutha Leader|            Otago|1876-10-27|false|SATURDAY, OCTOBER...|SATURDAY, OCTOBER...|\n",
      "|2255241|    Grey River Argus|       West Coast|1869-10-30| true|Page 1 Advertisem...|TJOUNDABY TIMBER ...|\n",
      "|2703510|New Zealand Gazet...|       Wellington|1842-08-13| true|Page 4 Advertisem...|! Heifers in Calf...|\n",
      "|3143807|Daily Southern Cross|         Auckland|1863-10-24|false|QUEEN'S REDOUBT. ...|QUEEN'S REDOUBT. ...|\n",
      "|3358839|       Te Aroha News|          Waikato|1887-06-04|false|THE CALIFORNIAN S...|THE CALIFORNIAN S...|\n",
      "|3431907|            Colonist|           Nelson|1859-11-15|false|     COPPER COINAGE.|COPPER COINAGE.Wi...|\n",
      "|3482586|Wellington Indepe...|       Wellington|1862-04-11|false|THE AMERICAN BLOC...|THE AMERICAN BLOC...|\n",
      "|3622567|  Wanganui Chronicle|Manawatu-Wanganui|1875-03-10| true|Page 1 Advertisem...|BUSINESS CARDS. W...|\n",
      "|3785597|     Wanganui Herald|Manawatu-Wanganui|1877-09-08|false|         COMMERCIAL.|COMMERCIAL.1 'Mes...|\n",
      "|3852255|   Otago Daily Times|            Otago|1863-04-09| true|Page 1 Advertisem...|Shipping Notice. ...|\n",
      "|3982952|     Wanganui Herald|Manawatu-Wanganui|1878-01-14|false|        VERY LATEST.|VERY LATEST.Londo...|\n",
      "|4313773|            Observer|         Auckland|1891-07-04|false|            PARNELL.|PARNELL.Matty, th...|\n",
      "|5002349|  Wanganui Chronicle|Manawatu-Wanganui|1878-07-29|false|       CHRISTCHURCH.|CHRISTCHURCH.,y ...|\n",
      "|5280288|         Thames Star|          Waikato|1878-10-10|false|           BLENHEIM.|BLENHEIM., This d...|\n",
      "|5322362| Nelson Evening Mail|           Nelson|1874-08-08|false|BY ELECTRIC TELEG...|BY ELECTRIC TELEG...|\n",
      "|5838766|     Wanganui Herald|Manawatu-Wanganui|1881-05-02| true|Page 4 Advertisem...|b'Business, adver...|\n",
      "|5925320|       Feilding Star|Manawatu-Wanganui|1897-04-27| true|Page 3 Advertisem...|Cash Exchange Co-...|\n",
      "|6078274|     Southland Times|            Otago|1878-01-28|false|  DUNEDIN, Saturday.|DUNEDIN, Saturday...|\n",
      "|6169978|            Observer|         Auckland|1901-09-14| true|Page 23 Advertise...|b'\\xe2\\x80\\xa2gRO...|\n",
      "|6261054|     Wanganui Herald|Manawatu-Wanganui|1882-02-21|false|    THE S.S. WAKATU.|b'THE S.S. WAKATU...|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.sample(False, 0.00001).limit(20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Save Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dataset for Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataframe would be our final dataset to generate metadata and subset to analyze and visualize, let's save it as compressed csv file to save time for later processes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../data/dataset'\n",
    "df.write.csv(path, mode='overwrite', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the clean dataset size:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw   dataset size: 33G\n",
      "clean dataset size: 14G\n"
     ]
    }
   ],
   "source": [
    "path = r'../data/papers_past'\n",
    "print('raw   dataset size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))\n",
    "path = r'../data/dataset'\n",
    "print('clean dataset size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After processing and compressing, the dataset reduce from 33GB to 14GB.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Dataset for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataset would be the full dataset for MALLET topic modeling, we will use this trained topic model to infer topic models of subset to analyze and visualize.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(F.col('id'), F.col('title'), F.col('content'))\n",
    "print('Shape of dataframe: ({}, {})'.format(df.count(), len(df.columns)))\n",
    "\n",
    "path = r'../data/train'\n",
    "df.write.csv(path, mode='overwrite', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../data/train'\n",
    "print('dataset-to-train size:', subprocess.check_output(['du','-sh', path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
