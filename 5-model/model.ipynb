{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Topic Modeling\n",
    "---\n",
    "### Papers Past Topic Modeling\n",
    "<br/>\n",
    "\n",
    "Ben Faulks - bmf43@uclive.ac.nz\n",
    "\n",
    "Xiandong Cai - xca24@uclive.ac.nz\n",
    "\n",
    "Yujie Cui - ycu23@uclive.ac.nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.app.name', 'local'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.driver.host', '192.168.1.207'),\n",
      " ('spark.driver.memory', '62g'),\n",
      " ('spark.master', 'local[*]'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.app.id', 'local-1547866356564'),\n",
      " ('spark.driver.port', '34203'),\n",
      " ('spark.ui.showConsoleProgress', 'true'),\n",
      " ('spark.driver.cores', '6'),\n",
      " ('spark.driver.maxResultSize', '4g')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.207:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=local>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "sys.path.insert(0, '../utils') # for import customed modules\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from utils_load import conf_pyspark, load_dataset\n",
    "\n",
    "# intiate PySpark\n",
    "sc, spark = conf_pyspark()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this part, we will perform following operations:**\n",
    "\n",
    "1. training a topic model using full dataset by MALLET, getting a topic model and topic words;\n",
    "1. splitting several subsets by random, by range of time, by region, and by advertisements;\n",
    "1. inferring subsets from the topic model of full dataset, getting doc-topic matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since MALLET can take one instance per file or one file one instance per line, the only choice for us is one file one instance per line, we need to transform the** `*.csv.gz` **file to one** `.csv` **file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/train/*.csv.gz > ../data/train/train.csv.gz\n",
    "\n",
    "gunzip ../data/train/train.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160140 ../data/train/train.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/train/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854244</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>T7JOUND, a set of Pekoe Straps, The JJ owner m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854262</td>\n",
       "      <td>THE CHRISTIAN CHURCH.</td>\n",
       "      <td>THE CHRISTIAN CHURCH.We have heard of an objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854275</td>\n",
       "      <td>Page 1 Advertisements Column 2</td>\n",
       "      <td>NOTE PAPER, Bill Paper, Envelopes Memorandum B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854588</td>\n",
       "      <td>THE EASTERN CRISIS.</td>\n",
       "      <td>THE EASTERN CRISIS.[reuieu's telegrams— copyri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854232  Page 1 Advertisements Column 1   \n",
       "1  1854244  Page 4 Advertisements Column 1   \n",
       "2  1854262           THE CHRISTIAN CHURCH.   \n",
       "3  1854275  Page 1 Advertisements Column 2   \n",
       "4  1854588             THE EASTERN CRISIS.   \n",
       "\n",
       "                                                   2  \n",
       "0  NOTICE.—This Ne?vspaper may b? sent Free by Po...  \n",
       "1  T7JOUND, a set of Pekoe Straps, The JJ owner m...  \n",
       "2  THE CHRISTIAN CHURCH.We have heard of an objec...  \n",
       "3  NOTE PAPER, Bill Paper, Envelopes Memorandum B...  \n",
       "4  THE EASTERN CRISIS.[reuieu's telegrams— copyri...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/train/train.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Training Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We do not think of the number of topics as a natural characteristic of corpora. The topic number is not really combinations of multinomial distributions, so there is no \"right\" topic number. We think of the number of topics as the scale of a map of corpora. If we want a broad overview, we use a small topic number. If we want more detail, use a larger topic number. The right number is the value that produces meaningful results that allow us to accomplish our goal.**\n",
    "\n",
    "**There is a wide range of good values for us, here we will train the dataset to get a topic model with 500 topics.**\n",
    "\n",
    "**Many metric methods and tools could help us to quantitatively tune the topic number,  such as [ldatuning](https://cran.r-project.org/web/packages/ldatuning/vignettes/topics.html) and [topic coherence](https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/), those evaluate work could be our future work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "%%time\n",
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/train/train.csv' -o './model_train' -p 'train';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training log to file. This way to avoid MALLET print very long log in notebook.\n",
    "with open('./model_train/train.log', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output files are:**\n",
    "* topics words from 'topicKeys.txt'\n",
    "* topics distribution per document from 'topicKeys.txt'\n",
    "* topic inferencer for inferring subset from 'inferencer.model'\n",
    "* corpus that topics belong to from 'stat.gz'\n",
    "* statistic info from 'diagnostics.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Except analyze and visualize topic model of full dataset, based on typical application scenario, we could extract several subsets from the full dataset to focus on specific point to analyze.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, load clean dataset and check dimension:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (320280, 7)\n",
      "+--------+----------------+----------+----------+-----+--------------------+--------------------+\n",
      "|      id|       publisher|    region|      date|  ads|               title|             content|\n",
      "+--------+----------------+----------+----------+-----+--------------------+--------------------+\n",
      "| 7517230|Grey River Argus|West Coast|1883-11-13|false|ANOTHER BOATING F...|b'ANOTHER BOATING...|\n",
      "| 8167584|West Coast Times|West Coast|1880-12-10|false| THE OPUNAKE MURDER.|b'THE OPUNAKE MUR...|\n",
      "|10970957|   Timaru Herald|Canterbury|1893-06-27|false|            CRICKET.|CRICKET.LORD SHEF...|\n",
      "|19188173|    Evening Post|Wellington|1934-12-03|false|     UMBER YARD FIRE|UMBER YARD FIRE(B...|\n",
      "+--------+----------------+----------+----------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = load_dataset('dataset', spark)\n",
    "df = load_dataset('dev', spark) # for developement\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df.count(), len(df.columns)))\n",
    "df.sample(False, 0.00001).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 By Range of Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For instance, we are interested in the topics in the papers during WWI, so we will research the topic models around the WWI. As wikipedia define it was lasted from 28/7/1914 to 11/11/1918, we expand the time from 1912 to 1921 to analyze and visualize topics during these time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decide start date and end date to sample:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '1912-01-01'\n",
    "END = '1921-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter samples between start and end date, remove advertisements, and generate the subset - wwi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (59578, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove advertisements, sampling subset, and select columns.\n",
    "df_sub = (\n",
    "    df.filter((df['ads'] == False) & (df['date'] >= START) & (df['date'] <= END))\n",
    ")\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the date range of the subset is correct:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1921, 12, 31), datetime.date(1912, 1, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_sub.select(F.max(F.col('date')).alias('MAX')).limit(1).collect()[0].MAX, \n",
    " df_sub.select(F.min(F.col('date')).alias('MIN')).limit(1).collect()[0].MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate subset to infer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (59578, 3)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_sub.select(F.col('id'), F.col('title'), F.col('content')).orderBy('id')\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save subset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save subset to ../data/subset/wwi\n",
      "subset size: 20M\n"
     ]
    }
   ],
   "source": [
    "subset_path = r'../data/subset/wwi'\n",
    "\n",
    "df_sub.write.csv(subset_path, sep='\\t', mode='overwrite', compression='gzip')\n",
    "\n",
    "print('Save subset to', subset_path)\n",
    "print('subset size:', subprocess.check_output(['du','-sh', subset_path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 By Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 16 regions in the full dataset, we focus on the regions that have the most population now (Auckland, Wellington, Canterbury and Otago).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decide regions to sample:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Auckland', 'Wellington', 'Canterbury', 'Otago']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter samples of target regions, remove advertisements, and generate the subset - regions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (156144, 7)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df.filter(F.col('region').isin(regions))\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check region in the subset is correct:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    region|\n",
      "+----------+\n",
      "|Wellington|\n",
      "|  Auckland|\n",
      "|     Otago|\n",
      "|Canterbury|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sub.select(F.col('region')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate subset to infer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (156144, 3)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_sub.select(F.col('id'), F.col('title'), F.col('content')).orderBy('id')\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save subset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save subset to ../data/subset/regions\n",
      "subset size: 83M\n"
     ]
    }
   ],
   "source": [
    "subset_path = r'../data/subset/regions'\n",
    "\n",
    "df_sub.write.csv(subset_path, sep='\\t', mode='overwrite', compression='gzip')\n",
    "\n",
    "print('Save subset to', subset_path)\n",
    "print('subset size:', subprocess.check_output(['du','-sh', subset_path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 By Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is only one label (ads) in the dataset, marks the sample/row/document/text is an advertisemet or not. Advertisements are less information than articles in news paper. However, they are useful to analyze the life of old time. Advertisements take account 27.4% in the full dataset, we extract a subset for advertisements.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter samples of advertisements, and generate the subset - ads:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (88350, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove advertisements, sampling subset, and select columns.\n",
    "df_sub = df.filter(F.col('ads') == True)\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check labels in the subset are all \"ads\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| ads|\n",
      "+----+\n",
      "|true|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sub.select(F.col('ads')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate subset to infer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (88350, 3)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_sub.select(F.col('id'), F.col('title'), F.col('content')).orderBy('id')\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save subset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save subset to ../data/subset/ads\n",
      "subset size: 59M\n"
     ]
    }
   ],
   "source": [
    "subset_path = r'../data/subset/ads'\n",
    "\n",
    "df_sub.write.csv(subset_path, sep='\\t', mode='overwrite', compression='gzip')\n",
    "\n",
    "print('Save subset to', subset_path)\n",
    "print('subset size:', subprocess.check_output(['du','-sh', subset_path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Inferring Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We infer subset by inferencer to get doc-topic matrix to analyze and visualize topics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 By Range of Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The same with training full dataset, we transform multiple compressed files to one** `*.csv` **file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/subset/wwi/*.csv.gz > ../data/subset/wwi/wwi.csv.gz\n",
    "\n",
    "gunzip ../data/subset/wwi/wwi.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59578 ../data/subset/wwi/wwi.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/subset/wwi/wwi.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3025974</td>\n",
       "      <td>Confirmations at Te Aute.</td>\n",
       "      <td>Confirmations at Te Aute.During the last quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3025974</td>\n",
       "      <td>Confirmations at Te Aute.</td>\n",
       "      <td>Confirmations at Te Aute.During the last quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3034188</td>\n",
       "      <td>Diocesan Notes.</td>\n",
       "      <td>Diocesan Notes.A recent letter received from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3034188</td>\n",
       "      <td>Diocesan Notes.</td>\n",
       "      <td>Diocesan Notes.A recent letter received from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3042724</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>We all want quiet ; we all want beauty for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                          1  \\\n",
       "0  3025974  Confirmations at Te Aute.   \n",
       "1  3025974  Confirmations at Te Aute.   \n",
       "2  3034188            Diocesan Notes.   \n",
       "3  3034188            Diocesan Notes.   \n",
       "4  3042724                   Untitled   \n",
       "\n",
       "                                                   2  \n",
       "0  Confirmations at Te Aute.During the last quart...  \n",
       "1  Confirmations at Te Aute.During the last quart...  \n",
       "2  Diocesan Notes.A recent letter received from t...  \n",
       "3  Diocesan Notes.A recent letter received from t...  \n",
       "4  We all want quiet ; we all want beauty for the...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/subset/wwi/wwi.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/subset/wwi/wwi.csv\n",
      "OutputDir=./model_wwi\n",
      "Process=infer\n",
      "AllDir=./model_train\n",
      "Inferencer=./model_train/inferencer.model\n",
      "CORES=6\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=250\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "IDFMIN=1\n",
      "IDFMAX=10\n",
      "19:24:22 :: Start import dataset...\n",
      "Import file already exist, nothing to do.\n",
      "19:24:22 :: Imported.\n",
      "Pruned model already exist, nothing to do.\n",
      "19:24:22 :: Pruned.\n",
      "19:24:22 :: Start infering dataset...\n",
      "20:13:10 :: Inferred.\n",
      "CPU times: user 28 ms, sys: 36 ms, total: 64 ms\n",
      "Wall time: 48min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/subset/wwi/wwi.csv' -o './model_wwi' -p 'infer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 By Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfor dataset files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/subset/regions/*.csv.gz > ../data/subset/regions/regions.csv.gz\n",
    "\n",
    "gunzip ../data/subset/regions/regions.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156144 ../data/subset/regions/regions.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/subset/regions/regions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854244</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>T7JOUND, a set of Pekoe Straps, The JJ owner m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854244</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>T7JOUND, a set of Pekoe Straps, The JJ owner m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854262</td>\n",
       "      <td>THE CHRISTIAN CHURCH.</td>\n",
       "      <td>THE CHRISTIAN CHURCH.We have heard of an objec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854232  Page 1 Advertisements Column 1   \n",
       "1  1854232  Page 1 Advertisements Column 1   \n",
       "2  1854244  Page 4 Advertisements Column 1   \n",
       "3  1854244  Page 4 Advertisements Column 1   \n",
       "4  1854262           THE CHRISTIAN CHURCH.   \n",
       "\n",
       "                                                   2  \n",
       "0  NOTICE.—This Ne?vspaper may b? sent Free by Po...  \n",
       "1  NOTICE.—This Ne?vspaper may b? sent Free by Po...  \n",
       "2  T7JOUND, a set of Pekoe Straps, The JJ owner m...  \n",
       "3  T7JOUND, a set of Pekoe Straps, The JJ owner m...  \n",
       "4  THE CHRISTIAN CHURCH.We have heard of an objec...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/subset/regions/regions.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/subset/regions/regions.csv\n",
      "OutputDir=./model_regions\n",
      "Process=infer\n",
      "AllDir=./model_train\n",
      "Inferencer=./model_train/inferencer.model\n",
      "CORES=6\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=250\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "IDFMIN=1\n",
      "IDFMAX=10\n",
      "20:13:10 :: Start import dataset...\n",
      "Import file already exist, nothing to do.\n",
      "20:13:10 :: Imported.\n",
      "Pruned model already exist, nothing to do.\n",
      "20:13:10 :: Pruned.\n",
      "20:13:10 :: Start infering dataset...\n",
      "20:17:49 :: Inferred.\n",
      "CPU times: user 8 ms, sys: 8 ms, total: 16 ms\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/subset/regions/regions.csv' -o './model_regions' -p 'infer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 By Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfor dataset files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/subset/ads/*.csv.gz > ../data/subset/ads/ads.csv.gz\n",
    "\n",
    "gunzip ../data/subset/ads/ads.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88350 ../data/subset/ads/ads.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/subset/ads/ads.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854244</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>T7JOUND, a set of Pekoe Straps, The JJ owner m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854244</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>T7JOUND, a set of Pekoe Straps, The JJ owner m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854275</td>\n",
       "      <td>Page 1 Advertisements Column 2</td>\n",
       "      <td>NOTE PAPER, Bill Paper, Envelopes Memorandum B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854232  Page 1 Advertisements Column 1   \n",
       "1  1854232  Page 1 Advertisements Column 1   \n",
       "2  1854244  Page 4 Advertisements Column 1   \n",
       "3  1854244  Page 4 Advertisements Column 1   \n",
       "4  1854275  Page 1 Advertisements Column 2   \n",
       "\n",
       "                                                   2  \n",
       "0  NOTICE.—This Ne?vspaper may b? sent Free by Po...  \n",
       "1  NOTICE.—This Ne?vspaper may b? sent Free by Po...  \n",
       "2  T7JOUND, a set of Pekoe Straps, The JJ owner m...  \n",
       "3  T7JOUND, a set of Pekoe Straps, The JJ owner m...  \n",
       "4  NOTE PAPER, Bill Paper, Envelopes Memorandum B...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/subset/ads/ads.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/subset/ads/ads.csv\n",
      "OutputDir=./model_ads\n",
      "Process=infer\n",
      "AllDir=./model_train\n",
      "Inferencer=./model_train/inferencer.model\n",
      "CORES=6\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=250\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "IDFMIN=1\n",
      "IDFMAX=10\n",
      "20:17:49 :: Start import dataset...\n",
      "Import file already exist, nothing to do.\n",
      "20:17:49 :: Imported.\n",
      "Pruned model already exist, nothing to do.\n",
      "20:17:49 :: Pruned.\n",
      "20:17:49 :: Start infering dataset...\n",
      "20:21:07 :: Inferred.\n",
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/subset/ads/ads.csv' -o './model_ads' -p 'infer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
