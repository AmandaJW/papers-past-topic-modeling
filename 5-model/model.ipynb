{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Topic Modeling\n",
    "---\n",
    "### Papers Past Topic Modeling\n",
    "<br/>\n",
    "\n",
    "Ben Faulks - bmf43@uclive.ac.nz\n",
    "\n",
    "Xiandong Cai - xca24@uclive.ac.nz\n",
    "\n",
    "Yujie Cui - ycu23@uclive.ac.nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.app.name', 'local'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.app.id', 'local-1547785755768'),\n",
      " ('spark.driver.port', '33895'),\n",
      " ('spark.driver.host', '192.168.1.207'),\n",
      " ('spark.driver.memory', '62g'),\n",
      " ('spark.master', 'local[*]'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.ui.showConsoleProgress', 'true'),\n",
      " ('spark.driver.cores', '6'),\n",
      " ('spark.driver.maxResultSize', '4g')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.207:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=local>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "sys.path.insert(0, '../utils') # for import customed modules\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from utils_data import conf_pyspark, load_dataset\n",
    "\n",
    "# intiate PySpark\n",
    "sc, spark = conf_pyspark()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this part, we will perform following operations:**\n",
    "\n",
    "1. training a topic model using full dataset by MALLET, getting a topic model and topic words;\n",
    "1. splitting several subsets by random, by range of time, by region, and by advertisements;\n",
    "1. inferring subsets from the topic model of full dataset, getting doc-topic matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since MALLET can take one instance per file or one file one instance per line, the only choice for us is one file one instance per line, we need to transform the** `*.csv.gz` **file to one** `.csv` **file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/train/*.csv.gz > ../data/train/dataset.csv.gz\n",
    "\n",
    "gunzip ../data/train/dataset.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16131646 ../data/train/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/train/dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854213</td>\n",
       "      <td>TO OUR HEADERS.</td>\n",
       "      <td>TO OUR HEADERS.; We have to apologize to our. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854214</td>\n",
       "      <td>GOD REST THEE, WEARY TRAVELLER.\\\"\\t\\\"GOD REST ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854215</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>v-/ .ADVERTISEMENTS. •- I Advertisements will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854216</td>\n",
       "      <td>Correspondence.</td>\n",
       "      <td>Correspondence.Ship \\ MatildavWattenbacti;\\\" J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854218</td>\n",
       "      <td>General News.</td>\n",
       "      <td>General News.lV AMus£MENTS.--^Our record of sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  \\\n",
       "0  1854213                                    TO OUR HEADERS.   \n",
       "1  1854214  GOD REST THEE, WEARY TRAVELLER.\\\"\\t\\\"GOD REST ...   \n",
       "2  1854215                     Page 1 Advertisements Column 1   \n",
       "3  1854216                                    Correspondence.   \n",
       "4  1854218                                      General News.   \n",
       "\n",
       "                                                   2  \n",
       "0  TO OUR HEADERS.; We have to apologize to our. ...  \n",
       "1                                                NaN  \n",
       "2  v-/ .ADVERTISEMENTS. •- I Advertisements will ...  \n",
       "3  Correspondence.Ship \\ MatildavWattenbacti;\\\" J...  \n",
       "4  General News.lV AMus£MENTS.--^Our record of sm...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/train/dataset.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Training Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/train/dataset.csv\n",
      "OutputDir=./model_all\n",
      "Process=train\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=500\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "17:29:54 :: Start import dataset...\n",
      "Import new data for training.\n",
      "17:29:54 :: Imported.\n",
      "17:29:54 :: Start training dataset...\n",
      "17:29:54 :: Trained.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/train/dataset.csv' -o './model_all' -p 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output files are:**\n",
    "* topics words from 'topicKeys.txt'\n",
    "* topics distribution per document from 'topicKeys.txt'\n",
    "* topic inferencer for inferring subset from 'inferencer.model'\n",
    "* corpus that topics belong to from 'stat.gz'\n",
    "* statistic info from 'diagnostics.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Except analyze and visualize topic model of full dataset, based on typical application scenario, we could extract several subsets from the full dataset to focus on specific point to analyze.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, load clean dataset and check dimension:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (16131646, 7)\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|     id|           publisher|           region|      date|  ads|               title|             content|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "|2019485|       Bush Advocate|      Hawke's Bay|1891-02-17|false|        FRISCO MAIL.|FRISCO MAIL.The n...|\n",
      "|2161884|     Lyttelton Times|       Canterbury|1858-07-31| true|Page 6 Advertisem...|SUMNER \" NOTICE T...|\n",
      "|2468499|       Clutha Leader|            Otago|1890-03-21| true|Page 1 Advertisem...|Business Notices....|\n",
      "|2593027|   Manawatu Standard|Manawatu-Wanganui|1883-05-18|false|  TO CORRESPONDENTS.|b'TO CORRESPONDEN...|\n",
      "|2728252|New Zealand Illus...|          unknown|1902-10-01|false|In Search of a Fo...|b'In Search of a ...|\n",
      "|2882510|   North Otago Times|            Otago|1868-06-26|false|            AUSTRIA.|AUSTRIA.A despatc...|\n",
      "|3284899|Nelson Examiner a...|           Nelson|1859-03-09| true|Page 3 Advertisem...|— » [From the Gov...|\n",
      "|3428696|      Mataura Ensign|            Otago|1892-09-13| true|Page 6 Advertisem...|The Faimerb' Agen...|\n",
      "|3518141|Waiapu Church Gaz...|          unknown|1943-10-01|false|THOUGHT FOR THE M...|THOUGHT FOR THE M...|\n",
      "|3520025|     Taranaki Herald|         Taranaki|1857-06-27|false|            AHURIRI.|AHURIRI.[From the...|\n",
      "+-------+--------------------+-----------------+----------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset('dataset', spark)\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df.count(), len(df.columns)))\n",
    "df.sample(False, 0.00001).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 By Range of Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For instance, we are interested in the topics in the papers during WWI, so we will research the topic models around the WWI. As wikipedia define it was lasted from 28/7/1914 to 11/11/1918, we expand the time from 1912 to 1921 to analyze and visualize topics during these time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decide start date and end date to sample:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '1912-01-01'\n",
    "END = '1921-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter samples between start and end date, remove advertisements, and generate the subset - wwi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (3002271, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove advertisements, sampling subset, and select columns.\n",
    "df_sub = (\n",
    "    df.filter((df['ads'] == False) & (df['date'] >= START) & (df['date'] <= END))\n",
    ")\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the date range of the subset is correct:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(1921, 12, 31), datetime.date(1912, 1, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_sub.select(F.max(F.col('date')).alias('MAX')).limit(1).collect()[0].MAX, \n",
    " df_sub.select(F.min(F.col('date')).alias('MIN')).limit(1).collect()[0].MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate subset to infer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (3002271, 3)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_sub.select(F.col('id'), F.col('title'), F.col('content')).orderBy('id')\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save subset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save subset to ../data/subset/wwi\n",
      "subset size: 1.7G\n"
     ]
    }
   ],
   "source": [
    "subset_path = r'../data/subset/wwi'\n",
    "\n",
    "df_sub.write.csv(subset_path, sep='\\t', mode='overwrite', compression='gzip')\n",
    "\n",
    "print('Save subset to', subset_path)\n",
    "print('subset size:', subprocess.check_output(['du','-sh', subset_path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 By Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 16 regions in the full dataset, we focus on the regions that have the most population now (Auckland, Wellington, Canterbury and Otago).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decide regions to sample:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Auckland', 'Wellington', 'Canterbury', 'Otago']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter samples of target regions, remove advertisements, and generate the subset - regions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (7889642, 7)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df.filter(F.col('region').isin(regions))\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check region in the subset is correct:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    region|\n",
      "+----------+\n",
      "|Wellington|\n",
      "|  Auckland|\n",
      "|     Otago|\n",
      "|Canterbury|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sub.select(F.col('region')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate subset to infer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (7889642, 3)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_sub.select(F.col('id'), F.col('title'), F.col('content')).orderBy('id')\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save subset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save subset to ../data/subset/regions\n",
      "subset size: 7.4G\n"
     ]
    }
   ],
   "source": [
    "subset_path = r'../data/subset/regions'\n",
    "\n",
    "df_sub.write.csv(subset_path, sep='\\t', mode='overwrite', compression='gzip')\n",
    "\n",
    "print('Save subset to', subset_path)\n",
    "print('subset size:', subprocess.check_output(['du','-sh', subset_path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 By Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is only one label (ads) in the dataset, marks the sample/row/document/text is an advertisemet or not. Advertisements are less information than articles in news paper. However, they are useful to analyze the life of old time. Advertisements take account 27.4% in the full dataset, we extract a subset for advertisements.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter samples of advertisements, and generate the subset - ads:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (4417669, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove advertisements, sampling subset, and select columns.\n",
    "df_sub = df.filter(F.col('ads') == True)\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check labels in the subset are all \"ads\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| ads|\n",
      "+----+\n",
      "|true|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sub.select(F.col('ads')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate subset to infer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (4417669, 3)\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_sub.select(F.col('id'), F.col('title'), F.col('content')).orderBy('id')\n",
    "\n",
    "print('Shape of dataframe: ({}, {})'.format(df_sub.count(), len(df_sub.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save subset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save subset to ../data/subset/ads\n",
      "subset size: 5.2G\n"
     ]
    }
   ],
   "source": [
    "subset_path = r'../data/subset/ads'\n",
    "\n",
    "df_sub.write.csv(subset_path, sep='\\t', mode='overwrite', compression='gzip')\n",
    "\n",
    "print('Save subset to', subset_path)\n",
    "print('subset size:', subprocess.check_output(['du','-sh', subset_path]).split()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Inferring Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We infer subset by inferencer to get doc-topic matrix to analyze and visualize topics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 By Range of Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The same with training full dataset, we transform multiple compressed files to one** `*.csv` **file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/subset/wwi/*.csv.gz > ../data/subset/wwi/wwi.csv.gz\n",
    "\n",
    "gunzip ../data/subset/wwi/wwi.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3002271 ../data/subset/wwi/wwi.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/subset/wwi/wwi.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3024444</td>\n",
       "      <td>The New Year.</td>\n",
       "      <td>The New Year.My Dear People,—-----t Although, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3024489</td>\n",
       "      <td>Committee on Social Questions.</td>\n",
       "      <td>Committee on Social Questions.Archdeacon Willi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3024508</td>\n",
       "      <td>The Church and Social Reform.</td>\n",
       "      <td>The Church and Social Reform.Two leading men m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3024532</td>\n",
       "      <td>Bible Teaching in Scbools.</td>\n",
       "      <td>Bible Teaching m Scbools.(By the Yen. Archdeac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3024551</td>\n",
       "      <td>Bishop's Diary.</td>\n",
       "      <td>Bishop's Diary.Bay of Plenty.November 29 : Lef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  3024444                   The New Year.   \n",
       "1  3024489  Committee on Social Questions.   \n",
       "2  3024508   The Church and Social Reform.   \n",
       "3  3024532      Bible Teaching in Scbools.   \n",
       "4  3024551                 Bishop's Diary.   \n",
       "\n",
       "                                                   2  \n",
       "0  The New Year.My Dear People,—-----t Although, ...  \n",
       "1  Committee on Social Questions.Archdeacon Willi...  \n",
       "2  The Church and Social Reform.Two leading men m...  \n",
       "3  Bible Teaching m Scbools.(By the Yen. Archdeac...  \n",
       "4  Bishop's Diary.Bay of Plenty.November 29 : Lef...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/subset/wwi/wwi.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/subset/wwi/wwi.csv\n",
      "OutputDir=./model_wwi\n",
      "Process=infer\n",
      "AllDir=./model_all\n",
      "Inferencer=./model_all/inferencer.model\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=500\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "17:59:34 :: Start import dataset...\n",
      "Import new data for inferring.\n",
      "17:59:34 :: Imported.\n",
      "17:59:34 :: Start infering dataset...\n",
      "17:59:34 :: Inferred.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/subset/wwi/wwi.csv' -o './model_wwi' -p 'infer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 By Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfor dataset files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/subset/regions/*.csv.gz > ../data/subset/regions/regions.csv.gz\n",
    "\n",
    "gunzip ../data/subset/regions/regions.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7889642 ../data/subset/regions/regions.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/subset/regions/regions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854213</td>\n",
       "      <td>TO OUR HEADERS.</td>\n",
       "      <td>TO OUR HEADERS.; We have to apologize to our. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854214</td>\n",
       "      <td>GOD REST THEE, WEARY TRAVELLER.\\\"\\t\\\"GOD REST ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854215</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>v-/ .ADVERTISEMENTS. •- I Advertisements will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854216</td>\n",
       "      <td>Correspondence.</td>\n",
       "      <td>Correspondence.Ship \\ MatildavWattenbacti;\\\" J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854218</td>\n",
       "      <td>General News.</td>\n",
       "      <td>General News.lV AMus£MENTS.--^Our record of sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  \\\n",
       "0  1854213                                    TO OUR HEADERS.   \n",
       "1  1854214  GOD REST THEE, WEARY TRAVELLER.\\\"\\t\\\"GOD REST ...   \n",
       "2  1854215                     Page 1 Advertisements Column 1   \n",
       "3  1854216                                    Correspondence.   \n",
       "4  1854218                                      General News.   \n",
       "\n",
       "                                                   2  \n",
       "0  TO OUR HEADERS.; We have to apologize to our. ...  \n",
       "1                                                NaN  \n",
       "2  v-/ .ADVERTISEMENTS. •- I Advertisements will ...  \n",
       "3  Correspondence.Ship \\ MatildavWattenbacti;\\\" J...  \n",
       "4  General News.lV AMus£MENTS.--^Our record of sm...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/subset/regions/regions.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/subset/regions/regions.csv\n",
      "OutputDir=./model_regions\n",
      "Process=infer\n",
      "AllDir=./model_all\n",
      "Inferencer=./model_all/inferencer.model\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=500\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "18:02:36 :: Start import dataset...\n",
      "Import new data for inferring.\n",
      "18:02:36 :: Imported.\n",
      "18:02:36 :: Start infering dataset...\n",
      "18:02:36 :: Inferred.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/subset/regions/regions.csv' -o './model_regions' -p 'infer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 By Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfor dataset files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/subset/ads/*.csv.gz > ../data/subset/ads/ads.csv.gz\n",
    "\n",
    "gunzip ../data/subset/ads/ads.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check lines/rows/samples/documents of dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4417669 ../data/subset/ads/ads.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l ../data/subset/ads/ads.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check contents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1854215</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>v-/ .ADVERTISEMENTS. •- I Advertisements will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1854231</td>\n",
       "      <td>Page 4 Advertisements Column 1</td>\n",
       "      <td>- Dr. Bell delivered a second Lecture on \\Or M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854232</td>\n",
       "      <td>Page 1 Advertisements Column 1</td>\n",
       "      <td>NOTICE.—This Ne?vspaper may b? sent Free by Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1854233</td>\n",
       "      <td>Page 1 Advertisements Column 2</td>\n",
       "      <td>TVT-OTR PAPER, Bill Paper, Envelopes _LV Memor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854234</td>\n",
       "      <td>Page 1 Advertisements Column 3</td>\n",
       "      <td>■ '■:.■ isles' . ■■■■■\\■ ■■'■ dining &amp; refresh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1  \\\n",
       "0  1854215  Page 1 Advertisements Column 1   \n",
       "1  1854231  Page 4 Advertisements Column 1   \n",
       "2  1854232  Page 1 Advertisements Column 1   \n",
       "3  1854233  Page 1 Advertisements Column 2   \n",
       "4  1854234  Page 1 Advertisements Column 3   \n",
       "\n",
       "                                                   2  \n",
       "0  v-/ .ADVERTISEMENTS. •- I Advertisements will ...  \n",
       "1  - Dr. Bell delivered a second Lecture on \\Or M...  \n",
       "2  NOTICE.—This Ne?vspaper may b? sent Free by Po...  \n",
       "3  TVT-OTR PAPER, Bill Paper, Envelopes _LV Memor...  \n",
       "4  ■ '■:.■ isles' . ■■■■■\\■ ■■'■ dining & refresh...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../data/subset/ads/ads.csv', header=None, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferring:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputFile=../data/subset/ads/ads.csv\n",
      "OutputDir=./model_ads\n",
      "Process=infer\n",
      "AllDir=./model_all\n",
      "Inferencer=./model_all/inferencer.model\n",
      "SEED1=1\n",
      "SEED2=1\n",
      "TOPICS=500\n",
      "ITERATION=2000\n",
      "INTERVAL=40\n",
      "BURNIN=300\n",
      "18:04:28 :: Start import dataset...\n",
      "Import new data for inferring.\n",
      "18:04:28 :: Imported.\n",
      "18:04:28 :: Start infering dataset...\n",
      "18:04:28 :: Inferred.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#! /bin/bash\n",
    "\n",
    "bash ./model.sh -i '../data/subset/ads/ads.csv' -o './model_ads' -p 'infer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
